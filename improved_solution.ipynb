{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import Levenshtein as lev\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import os\n",
    "import smart_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltable = pd.read_csv(join('data', \"ltable.csv\"))\n",
    "rtable = pd.read_csv(join('data', \"rtable.csv\"))\n",
    "train = pd.read_csv(join('data', \"train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltable['brand'] = ltable['brand'].astype(str)\n",
    "rtable['brand'] = rtable['brand'].astype(str)\n",
    "\n",
    "# get all brands\n",
    "brands_l = set(ltable[\"brand\"].values)\n",
    "brands_r = set(rtable[\"brand\"].values)\n",
    "brands = brands_l.union(brands_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1696202"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand2ids_l = {b.lower(): [[],[]] for b in brands}\n",
    "brand2ids_r = {b.lower(): [[],[]] for b in brands}\n",
    "\n",
    "# group the records by brand, recording their id and model numbers\n",
    "for i, x in ltable.iterrows():\n",
    "    brand2ids_l[x[\"brand\"].lower()][0].append(x[\"id\"])\n",
    "    brand2ids_l[x[\"brand\"].lower()][1].append(x[\"modelno\"])\n",
    "for i, x in rtable.iterrows():\n",
    "    brand2ids_r[x[\"brand\"].lower()][0].append(x[\"id\"])\n",
    "    brand2ids_r[x[\"brand\"].lower()][1].append(x[\"modelno\"])\n",
    "            \n",
    "candset = []\n",
    "for brd in brands:\n",
    "    l_ids = brand2ids_l[brd][0]\n",
    "    l_modelnos = brand2ids_l[brd][1]\n",
    "    \n",
    "    if brd.lower() != \"nan\":\n",
    "        # if the record has a brand, it can match with all matching brands\n",
    "        r_ids = brand2ids_r[brd][0]\n",
    "        r_modelnos = brand2ids_r[brd][1]\n",
    "        for i in range(len(l_ids)):\n",
    "            for j in range(len(r_ids)):\n",
    "                if ((type(l_modelnos[i]) == float) and (math.isnan(l_modelnos[i]))) or ((type(r_modelnos[j]) == float) and (math.isnan(r_modelnos[j]))):\n",
    "                    # it is a candidate pair if either model number is not input\n",
    "                    candset.append([l_ids[i], r_ids[j]])\n",
    "                elif lev.distance(l_modelnos[i],r_modelnos[j]) < 5:\n",
    "                    # it is a candidate pair if the model numbers are similar\n",
    "                    candset.append([l_ids[i], r_ids[j]])\n",
    "                    \n",
    "        # this record may also be a match with all records that have no brand\n",
    "        nan_r_ids = brand2ids_r[\"nan\"][0]\n",
    "        nan_r_modelnos = brand2ids_r[\"nan\"][1]\n",
    "        for i in range(len(l_ids)):\n",
    "            for j in range(len(nan_r_ids)):\n",
    "                if ((type(l_modelnos[i]) == float) and (math.isnan(l_modelnos[i]))) or ((type(nan_r_modelnos[j]) == float) and (math.isnan(nan_r_modelnos[j]))):\n",
    "                    # it is a candidate pair if either model number is not input\n",
    "                    candset.append([l_ids[i], nan_r_ids[j]])\n",
    "                elif lev.distance(l_modelnos[i],nan_r_modelnos[j]) < 5:\n",
    "                    # it is a candidate pair if the model numbers are similar\n",
    "                    candset.append([l_ids[i], nan_r_ids[j]])\n",
    "                \n",
    "    else:\n",
    "        # if the record does not have a brand, it might be a match with any other record\n",
    "        for sub_brd in brands:\n",
    "            r_ids = brand2ids_r[sub_brd][0]\n",
    "            r_modelnos = brand2ids_r[sub_brd][1]\n",
    "            for i in range(len(l_ids)):\n",
    "                for j in range(len(r_ids)):\n",
    "                    if ((type(l_modelnos[i]) == float) and (math.isnan(l_modelnos[i]))) or ((type(r_modelnos[j]) == float) and (math.isnan(r_modelnos[j]))):\n",
    "                        # it is a candidate pair if either model number is not input\n",
    "                        candset.append([l_ids[i], r_ids[j]])\n",
    "                    elif lev.distance(l_modelnos[i],r_modelnos[j]) < 5:\n",
    "                        # it is a candidate pair if the model numbers are similar\n",
    "                        candset.append([l_ids[i], r_ids[j]])\n",
    "        \n",
    "len(candset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs2LR(ltable, rtable, candset):\n",
    "    ltable.index = ltable.id\n",
    "    rtable.index = rtable.id\n",
    "    pairs = np.array(candset)\n",
    "    tpls_l = ltable.loc[pairs[:, 0], :]\n",
    "    tpls_r = rtable.loc[pairs[:, 1], :]\n",
    "    tpls_l.columns = [col + \"_l\" for col in tpls_l.columns]\n",
    "    tpls_r.columns = [col + \"_r\" for col in tpls_r.columns]\n",
    "    tpls_l.reset_index(inplace=True, drop=True)\n",
    "    tpls_r.reset_index(inplace=True, drop=True)\n",
    "    LR = pd.concat([tpls_l, tpls_r], axis=1)\n",
    "    return LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_l</th>\n",
       "      <th>title_l</th>\n",
       "      <th>category_l</th>\n",
       "      <th>brand_l</th>\n",
       "      <th>modelno_l</th>\n",
       "      <th>price_l</th>\n",
       "      <th>id_r</th>\n",
       "      <th>title_r</th>\n",
       "      <th>category_r</th>\n",
       "      <th>brand_r</th>\n",
       "      <th>modelno_r</th>\n",
       "      <th>price_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>664</td>\n",
       "      <td>adobe photoshop and premiere elements 9 window...</td>\n",
       "      <td>software</td>\n",
       "      <td>adobe</td>\n",
       "      <td>65087226</td>\n",
       "      <td>140.7</td>\n",
       "      <td>221</td>\n",
       "      <td>contribute cs5 windows</td>\n",
       "      <td>office electronics</td>\n",
       "      <td>adobe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>664</td>\n",
       "      <td>adobe photoshop and premiere elements 9 window...</td>\n",
       "      <td>software</td>\n",
       "      <td>adobe</td>\n",
       "      <td>65087226</td>\n",
       "      <td>140.7</td>\n",
       "      <td>299</td>\n",
       "      <td>new-after effects cs5 .5 mac - adbcd21041mc</td>\n",
       "      <td>gps mapping software</td>\n",
       "      <td>adobe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1435.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>664</td>\n",
       "      <td>adobe photoshop and premiere elements 9 window...</td>\n",
       "      <td>software</td>\n",
       "      <td>adobe</td>\n",
       "      <td>65087226</td>\n",
       "      <td>140.7</td>\n",
       "      <td>311</td>\n",
       "      <td>illustrator cs5 windows</td>\n",
       "      <td>printers</td>\n",
       "      <td>adobe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>664</td>\n",
       "      <td>adobe photoshop and premiere elements 9 window...</td>\n",
       "      <td>software</td>\n",
       "      <td>adobe</td>\n",
       "      <td>65087226</td>\n",
       "      <td>140.7</td>\n",
       "      <td>2427</td>\n",
       "      <td>adobe premiere pro cs 5.5 software for mac etail</td>\n",
       "      <td>monitor accessories</td>\n",
       "      <td>adobe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>399.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>664</td>\n",
       "      <td>adobe photoshop and premiere elements 9 window...</td>\n",
       "      <td>software</td>\n",
       "      <td>adobe</td>\n",
       "      <td>65087226</td>\n",
       "      <td>140.7</td>\n",
       "      <td>2428</td>\n",
       "      <td>adobe creative suite cs5 design premium for wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adobe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1375.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696197</th>\n",
       "      <td>1721</td>\n",
       "      <td>five star 5-subject wirebound trend notebook w...</td>\n",
       "      <td>stationery &amp; office machinery</td>\n",
       "      <td>five star</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17765</td>\n",
       "      <td>new-five star 06208 - wirebound notebook colle...</td>\n",
       "      <td>storage presentation materials</td>\n",
       "      <td>five star</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696198</th>\n",
       "      <td>1721</td>\n",
       "      <td>five star 5-subject wirebound trend notebook w...</td>\n",
       "      <td>stationery &amp; office machinery</td>\n",
       "      <td>five star</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17766</td>\n",
       "      <td>new-five star 06112 - trend wirebound notebook...</td>\n",
       "      <td>storage presentation materials</td>\n",
       "      <td>five star</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696199</th>\n",
       "      <td>1721</td>\n",
       "      <td>five star 5-subject wirebound trend notebook w...</td>\n",
       "      <td>stationery &amp; office machinery</td>\n",
       "      <td>five star</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16165</td>\n",
       "      <td>dock connector to usb 2.0 cable for ipod and i...</td>\n",
       "      <td>cables interconnects</td>\n",
       "      <td>nan</td>\n",
       "      <td>m9569g/a</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696200</th>\n",
       "      <td>1721</td>\n",
       "      <td>five star 5-subject wirebound trend notebook w...</td>\n",
       "      <td>stationery &amp; office machinery</td>\n",
       "      <td>five star</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21188</td>\n",
       "      <td>htc evo 4g 3500mah extended battery cover</td>\n",
       "      <td>batteries</td>\n",
       "      <td>nan</td>\n",
       "      <td>evo 4g</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696201</th>\n",
       "      <td>800</td>\n",
       "      <td>diamond multimedia stealth ati radeon 9250 256...</td>\n",
       "      <td>electronics - general</td>\n",
       "      <td>diamond multimedia</td>\n",
       "      <td>s9250pci256sb</td>\n",
       "      <td>59.0</td>\n",
       "      <td>12960</td>\n",
       "      <td>radeon 6870 pcie 1gb</td>\n",
       "      <td>basic</td>\n",
       "      <td>diamond multimedia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1696202 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id_l                                            title_l  \\\n",
       "0         664  adobe photoshop and premiere elements 9 window...   \n",
       "1         664  adobe photoshop and premiere elements 9 window...   \n",
       "2         664  adobe photoshop and premiere elements 9 window...   \n",
       "3         664  adobe photoshop and premiere elements 9 window...   \n",
       "4         664  adobe photoshop and premiere elements 9 window...   \n",
       "...       ...                                                ...   \n",
       "1696197  1721  five star 5-subject wirebound trend notebook w...   \n",
       "1696198  1721  five star 5-subject wirebound trend notebook w...   \n",
       "1696199  1721  five star 5-subject wirebound trend notebook w...   \n",
       "1696200  1721  five star 5-subject wirebound trend notebook w...   \n",
       "1696201   800  diamond multimedia stealth ati radeon 9250 256...   \n",
       "\n",
       "                            category_l             brand_l      modelno_l  \\\n",
       "0                             software               adobe       65087226   \n",
       "1                             software               adobe       65087226   \n",
       "2                             software               adobe       65087226   \n",
       "3                             software               adobe       65087226   \n",
       "4                             software               adobe       65087226   \n",
       "...                                ...                 ...            ...   \n",
       "1696197  stationery & office machinery           five star            NaN   \n",
       "1696198  stationery & office machinery           five star            NaN   \n",
       "1696199  stationery & office machinery           five star            NaN   \n",
       "1696200  stationery & office machinery           five star            NaN   \n",
       "1696201          electronics - general  diamond multimedia  s9250pci256sb   \n",
       "\n",
       "         price_l   id_r                                            title_r  \\\n",
       "0          140.7    221                             contribute cs5 windows   \n",
       "1          140.7    299        new-after effects cs5 .5 mac - adbcd21041mc   \n",
       "2          140.7    311                            illustrator cs5 windows   \n",
       "3          140.7   2427   adobe premiere pro cs 5.5 software for mac etail   \n",
       "4          140.7   2428  adobe creative suite cs5 design premium for wi...   \n",
       "...          ...    ...                                                ...   \n",
       "1696197      5.0  17765  new-five star 06208 - wirebound notebook colle...   \n",
       "1696198      5.0  17766  new-five star 06112 - trend wirebound notebook...   \n",
       "1696199      5.0  16165  dock connector to usb 2.0 cable for ipod and i...   \n",
       "1696200      5.0  21188          htc evo 4g 3500mah extended battery cover   \n",
       "1696201     59.0  12960                               radeon 6870 pcie 1gb   \n",
       "\n",
       "                             category_r             brand_r modelno_r  price_r  \n",
       "0                    office electronics               adobe       NaN      NaN  \n",
       "1                  gps mapping software               adobe       NaN  1435.06  \n",
       "2                              printers               adobe       NaN      NaN  \n",
       "3                   monitor accessories               adobe       NaN   399.95  \n",
       "4                                   NaN               adobe       NaN  1375.00  \n",
       "...                                 ...                 ...       ...      ...  \n",
       "1696197  storage presentation materials           five star       NaN    21.00  \n",
       "1696198  storage presentation materials           five star       NaN    21.00  \n",
       "1696199            cables interconnects                 nan  m9569g/a     0.64  \n",
       "1696200                       batteries                 nan    evo 4g     6.70  \n",
       "1696201                           basic  diamond multimedia       NaN      NaN  \n",
       "\n",
       "[1696202 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candset_df = pairs2LR(ltable, rtable, candset)\n",
    "candset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24155,)\n"
     ]
    }
   ],
   "source": [
    "left_titles = np.unique(np.array(candset_df[\"title_l\"]).reshape(len(candset_df[\"title_l\"]),1))\n",
    "right_titles = np.unique(np.array(candset_df[\"title_r\"]).reshape(len(candset_df[\"title_r\"]),1))\n",
    "all_titles = np.concatenate([left_titles,right_titles],axis=0)\n",
    "print(all_titles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(documents, tokens_only=False):\n",
    "    for i, line in enumerate(documents):\n",
    "        tokens = [word for word in line.lower().split() if not word in remove_words]\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            # For training data, add tags\n",
    "            yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "title_corpus = list(read_corpus(all_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v = Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "d2v.build_vocab(train_corpus)\n",
    "d2v.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "#word_corpus = api.load('text8')\n",
    "#w2v = Word2Vec(word_corpus)\n",
    "w2v = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_words = stopwords.words('english')\n",
    "remove_punctuation = \"&.,-/\"\n",
    "\n",
    "def oh_cos_similarity(row, attr):\n",
    "    if (type(row[attr + \"_l\"]) == float) and math.isnan(row[attr + \"_l\"]):\n",
    "        return 0.5\n",
    "    if (type(row[attr + \"_r\"]) == float) and math.isnan(row[attr + \"_r\"]):\n",
    "        return 0.5\n",
    "    left_set = set(word for word in row[attr + \"_l\"].lower().split() if not word in remove_words)\n",
    "    right_set = set(word for word in row[attr + \"_r\"].lower().split() if not word in remove_words)\n",
    "    \n",
    "    if min(len(left_set),len(right_set)) == 0:\n",
    "        return 0.5\n",
    "    \n",
    "    left_phrase = []\n",
    "    right_phrase = []\n",
    "    vocabulary = left_set.union(right_set)\n",
    "    for term in vocabulary:\n",
    "        if term in left_set:\n",
    "            left_phrase.append(1)\n",
    "        else:\n",
    "            left_phrase.append(0)\n",
    "        if term in right_set:\n",
    "            right_phrase.append(1)\n",
    "        else:\n",
    "            right_phrase.append(0)\n",
    "    left_phrase = np.array(left_phrase)\n",
    "    right_phrase = np.array(right_phrase)\n",
    "    return (np.dot(left_phrase,right_phrase)/(np.linalg.norm(left_phrase)*np.linalg.norm(right_phrase)))\n",
    "\n",
    "def cos_similarity(row, attr):\n",
    "    if attr == \"title\":\n",
    "        left_sentence = [word for word in row[attr + \"_l\"].lower().split() if not word in remove_words]\n",
    "        right_sentence = [word for word in row[attr + \"_r\"].lower().split() if not word in remove_words]\n",
    "\n",
    "        left_phrase = d2v.infer_vector(left_sentence)\n",
    "        right_phrase = d2v.infer_vector(right_sentence)\n",
    "\n",
    "        return (np.dot(left_phrase,right_phrase)/(np.linalg.norm(left_phrase)*np.linalg.norm(right_phrase)))\n",
    "    \n",
    "    else:\n",
    "        if (type(row[attr + \"_l\"]) == float) and math.isnan(row[attr + \"_l\"]):\n",
    "            return 0.5\n",
    "        if (type(row[attr + \"_r\"]) == float) and math.isnan(row[attr + \"_r\"]):\n",
    "            return 0.5\n",
    "        \n",
    "        left_sentence = []\n",
    "        right_sentence = []\n",
    "        for word in row[attr + \"_l\"].lower().split():\n",
    "            if (word not in remove_words) and (word not in remove_punctuation):\n",
    "                if (word in w2v.key_to_index.keys()):\n",
    "                    left_sentence.append(word)\n",
    "        for word in row[attr + \"_r\"].lower().split():\n",
    "            if (word not in remove_words) and (word not in remove_punctuation):\n",
    "                if (word in w2v.key_to_index.keys()):\n",
    "                    right_sentence.append(word)\n",
    "        \n",
    "        if min(len(left_sentence),len(right_sentence)) == 0:\n",
    "            return 0.5\n",
    "        \n",
    "        left_phrase = np.zeros(300)\n",
    "        left_phrase += w2v[left_sentence[0]]\n",
    "        right_phrase = np.zeros(300)\n",
    "        right_phrase += w2v[right_sentence[0]]\n",
    "        \n",
    "        if len(left_sentence) > 1:\n",
    "            for i in range(1,len(left_sentence)):\n",
    "                left_phrase += w2v[left_sentence[i]]\n",
    "        if len(right_sentence) > 1:\n",
    "            for i in range(1,len(right_sentence)):\n",
    "                right_phrase += w2v[right_sentence[i]]\n",
    "                \n",
    "        return (np.dot(left_phrase,right_phrase)/(np.linalg.norm(left_phrase)*np.linalg.norm(right_phrase)))\n",
    "\n",
    "def jaccard_similarity(row, attr):\n",
    "    if (type(row[attr + \"_l\"]) == float) and math.isnan(row[attr + \"_l\"]):\n",
    "        return 0.5\n",
    "    if (type(row[attr + \"_r\"]) == float) and math.isnan(row[attr + \"_r\"]):\n",
    "        return 0.5\n",
    "    x = set(row[attr + \"_l\"].lower().split())\n",
    "    y = set(row[attr + \"_r\"].lower().split())\n",
    "    return len(x.intersection(y)) / max(len(x), len(y))\n",
    "\n",
    "\n",
    "def levenshtein_distance(row, attr):\n",
    "    if (type(row[attr + \"_l\"]) == float) and math.isnan(row[attr + \"_l\"]):\n",
    "        return 0\n",
    "    if (type(row[attr + \"_r\"]) == float) and math.isnan(row[attr + \"_r\"]):\n",
    "        return 0\n",
    "    x = row[attr + \"_l\"].lower()\n",
    "    y = row[attr + \"_r\"].lower()\n",
    "    return lev.distance(x, y)\n",
    "\n",
    "def price_difference(row):\n",
    "    if math.isnan(row[\"price_l\"]) or math.isnan(row[\"price_r\"]):\n",
    "        return 0\n",
    "    price_diff = abs(row[\"price_l\"] - row[\"price_r\"])\n",
    "    return price_diff\n",
    "\n",
    "def feature_engineering(LR):\n",
    "    #LR = LR.astype(str)\n",
    "    attrs = [\"title\",\"category\", \"brand\", \"modelno\"]\n",
    "    features = []\n",
    "    for attr in attrs:\n",
    "        if attr in [\"title\",\"category\"]:\n",
    "            cos_sim = LR.apply(cos_similarity, attr=attr, axis=1)\n",
    "            features.append(cos_sim)\n",
    "        if attr in [\"title\",\"modelno\"]:\n",
    "            oh_cos = LR.apply(bow_cos_similarity, attr=attr, axis=1)\n",
    "            features.append(oh_cos)\n",
    "        if attr in [\"title\",\"modelno\"]:\n",
    "            j_sim = LR.apply(jaccard_similarity, attr=attr, axis=1)\n",
    "            features.append(j_sim)\n",
    "        if attr in [\"title\",\"category\",\"modelno\"]:\n",
    "            l_dist = LR.apply(levenshtein_distance, attr=attr, axis=1)\n",
    "            features.append(l_dist)\n",
    "    price_diff = LR.apply(price_difference, axis=1)\n",
    "    features.append(price_diff)\n",
    "    features = np.array(features).T\n",
    "    return features\n",
    "\n",
    "candset_features = feature_engineering(candset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_pairs = list(map(tuple, train[[\"ltable_id\", \"rtable_id\"]].values))\n",
    "training_df = pairs2LR(ltable, rtable, training_pairs)\n",
    "training_features = feature_engineering(training_df)\n",
    "training_label = train.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0421687029866713\ttitle doc2vec\n",
      "0.07524834576397854\ttitle oh cos\n",
      "0.04363170690190277\ttitle Jaccard\n",
      "0.02343084960153141\ttitle Lev\n",
      "0.030601492842612155\tcategory word2vec\n",
      "0.007203602264163944\tcategory Lev\n",
      "0.12068319662730076\tmodelno oh cos\n",
      "0.1232435409938879\tmodelno Jaccard\n",
      "0.033554938668552525\tmodelno Lev\n",
      "0.01692923722028472\tprice diff\n"
     ]
    }
   ],
   "source": [
    "mi = mutual_info_classif(training_features,training_label)\n",
    "feature_labs = [\"title doc2vec\", \"title oh cos\", \"title Jaccard\", \"title Lev\",\n",
    "                \"category word2vec\", \"category Lev\",\n",
    "                \"modelno oh cos\", \"modelno Jaccard\", \"modelno Lev\",\n",
    "                \"price diff\"]\n",
    "for i in range(len(mi)):\n",
    "    print(str(mi[i])+\"\\t\"+feature_labs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734691669139111\n",
      "{'max_depth': 10, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(class_weight=\"balanced_subsample\",n_jobs=-1)\n",
    "rf_gscv = GridSearchCV(rf,scoring=\"f1\",param_grid={\n",
    "    \"n_estimators\":[50,100,200,300,400,500], \"max_depth\":[5,10,15,20,25]\n",
    "},cv=5,n_jobs=-1)\n",
    "rf_gscv.fit(training_features, training_label)\n",
    "best_clf = rf_gscv.best_estimator_\n",
    "print(rf_gscv.best_score_)\n",
    "print(rf_gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:\t\t0.7286442473189462\tVar:\t0.013409284529097428\n",
      "Recall:\t\t0.6297872340425532\tVar:\t0.033909313724487716\n",
      "Precision:\t0.8684829991281605\tVar:\t0.03463191230562473\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "for train_index, test_index in kf.split(training_features, training_label):\n",
    "    reduced_data_train = training_features[train_index]\n",
    "    reduced_labels_train = training_label[train_index]\n",
    "    \n",
    "    reduced_data_test = training_features[test_index]\n",
    "    reduced_labels_test = training_label[test_index]\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=200,max_depth=10,class_weight=\"balanced_subsample\")\n",
    "    clf.fit(reduced_data_train, reduced_labels_train)\n",
    "    \n",
    "    y_pred = clf.predict(reduced_data_test)\n",
    "    f1s.append(f1_score(reduced_labels_test,y_pred))\n",
    "    recalls.append(recall_score(reduced_labels_test,y_pred))\n",
    "    precisions.append(precision_score(reduced_labels_test,y_pred))\n",
    "f1s = np.array(f1s)\n",
    "recalls = np.array(recalls)\n",
    "precisions = np.array(precisions)\n",
    "print(\"F1:\\t\\t{}\\tVar:\\t{}\".format(f1s.mean(),f1s.std()))\n",
    "print(\"Recall:\\t\\t{}\\tVar:\\t{}\".format(recalls.mean(),recalls.std()))\n",
    "print(\"Precision:\\t{}\\tVar:\\t{}\".format(precisions.mean(),precisions.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_y_pred = best_clf.predict(candset_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_pairs = candset_df.loc[cand_y_pred == 1, [\"id_l\", \"id_r\"]]\n",
    "matching_pairs = list(map(tuple, matching_pairs.values))\n",
    "\n",
    "matching_pairs_in_training = training_df.loc[training_label == 1, [\"id_l\", \"id_r\"]]\n",
    "matching_pairs_in_training = set(list(map(tuple, matching_pairs_in_training.values)))\n",
    "\n",
    "pred_pairs = [pair for pair in matching_pairs if\n",
    "              pair not in matching_pairs_in_training]  # remove the matching pairs already in training\n",
    "pred_pairs = np.array(pred_pairs)\n",
    "pred_df = pd.DataFrame(pred_pairs, columns=[\"ltable_id\", \"rtable_id\"])\n",
    "pred_df.to_csv(\"improved_output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
